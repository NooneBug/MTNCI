{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MTNCI import ShimaokaMTNCI\n",
    "import torch\n",
    "import sys \n",
    "sys.path.append('../figet-hyperbolic-space')\n",
    "import figet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class argClass():\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        self.emb_size = 300 \n",
    "        self.char_emb_size = 50 \n",
    "        self.positional_emb_size = 25 \n",
    "        self.context_rnn_size = 200\n",
    "        self.attn_size = 100\n",
    "        self.mention_dropout = 0.5\n",
    "        self.context_dropout = 0.5\n",
    "        \n",
    "if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "        \n",
    "lopez_data = torch.load('../figet-hyperbolic-space/data/prep/MTNCI-fair/data.pt')        \n",
    "\n",
    "args = {'emb_size': 300, 'char_emb_size': 50, 'positional_emb_size': 25, 'context_rnn_size':200,\n",
    "        'attn_size': 100, 'mention_dropout' : 0.5, 'context_dropout': 0.5}\n",
    "args = argClass(args)\n",
    "vocabs = lopez_data['vocabs']\n",
    "SHIMAOKA_OUT = args.context_rnn_size * 2 + args.emb_size + args.char_emb_size\n",
    "out_spec = [{'manifold':'euclid', 'dim':[64, 10]},\n",
    "            {'manifold':'poincare', 'dim':[128, 128, 10]}]\n",
    "\n",
    "model = ShimaokaMTNCI(args, vocabs, device, \n",
    "                    input_d=SHIMAOKA_OUT,\n",
    "                    out_spec = out_spec,\n",
    "                    dims = [512, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShimaokaMTNCI(\n",
       "  (common_network): CommonLayer(\n",
       "    (fully): ModuleList(\n",
       "      (0): Linear(in_features=750, out_features=512, bias=True)\n",
       "      (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "    (bns): ModuleList(\n",
       "      (0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (leaky_relu): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (out_layers): ModuleList(\n",
       "    (0): RegressionOutput(\n",
       "      (out): ModuleList(\n",
       "        (0): Linear(in_features=512, out_features=64, bias=True)\n",
       "        (1): Linear(in_features=64, out_features=10, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (leaky_relu): ReLU()\n",
       "      (bns): ModuleList(\n",
       "        (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): RegressionOutput(\n",
       "      (out): ModuleList(\n",
       "        (0): MobiusLinear(\n",
       "          in_features=512, out_features=128, bias=True\n",
       "          (ball): Poincare ball manifold\n",
       "        )\n",
       "        (1): MobiusLinear(\n",
       "          in_features=128, out_features=128, bias=True\n",
       "          (ball): Poincare ball manifold\n",
       "        )\n",
       "        (2): MobiusLinear(\n",
       "          in_features=128, out_features=10, bias=True\n",
       "          (ball): Poincare ball manifold\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (leaky_relu): ReLU()\n",
       "      (bns): ModuleList(\n",
       "        (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (word_lut): Embedding(108792, 300, padding_idx=0)\n",
       "  (mention_encoder): MentionEncoder(\n",
       "    (char_encoder): CharEncoder(\n",
       "      (char_W): Embedding(115, 100, padding_idx=0)\n",
       "      (conv1d): Conv1d(100, 50, kernel_size=(5,), stride=(1,))\n",
       "    )\n",
       "    (attentive_weighted_average): SelfAttentiveSum(\n",
       "      (key_maker): Linear(in_features=300, out_features=1, bias=False)\n",
       "      (key_rel): ReLU()\n",
       "      (key_output): Linear(in_features=1, out_features=1, bias=False)\n",
       "      (key_softmax): Softmax(dim=1)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (context_encoder): ContextEncoder(\n",
       "    (pos_linear): Linear(in_features=1, out_features=25, bias=True)\n",
       "    (context_dropout): Dropout(p=0.5, inplace=False)\n",
       "    (rnn): LSTM(325, 200, batch_first=True, bidirectional=True)\n",
       "    (attention): SelfAttentiveSum(\n",
       "      (key_maker): Linear(in_features=400, out_features=100, bias=False)\n",
       "      (key_rel): ReLU()\n",
       "      (key_output): Linear(in_features=100, out_features=1, bias=False)\n",
       "      (key_softmax): Softmax(dim=1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard_run_ID = 'shimaoka_MTNCI_fair_sampled'\n",
    "\n",
    "model.set_checkpoint_path(checkpoint_path = '../source_files/checkpoints/{}'.format(tensorboard_run_ID))\n",
    "\n",
    "checkpoint = torch.load(model.checkpoint_path)\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(data, batch_size, key):\n",
    "    dataset = data[key]\n",
    "    dataset.set_batch_size(batch_size)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "test = get_dataset(lopez_data, 1024, \"test\")\n",
    "\n",
    "test_labels = [lopez_data['vocabs']['type'].idx2label[label.item()] for entry in test for labels in entry[5] for label in labels]\n",
    "\n",
    "test_entities = []\n",
    "for entry in test: \n",
    "    for entities in entry[3]:\n",
    "        entity_label = ''\n",
    "        for entity in entities:\n",
    "            if entity.item() != 0:\n",
    "                entity_label += lopez_data['vocabs']['token'].idx2label[entity.item()] + ' '\n",
    "        test_entities.append(entity_label)\n",
    "\n",
    "test_data = {'data': test, 'labels': test_labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "... loading concept embeddings ...\n",
      "concept embeddings loaded in 0.05 seconds\n"
     ]
    }
   ],
   "source": [
    "from DatasetManager import ShimaokaMTNCIDatasetManager as DatasetManager\n",
    "\n",
    "nickel = True\n",
    "\n",
    "FILE_ID = '16_3'\n",
    "\n",
    "SOURCE_FILES_PATH = '/datahdd/vmanuel/MTNCI_datasets/source_files/'\n",
    "\n",
    "EMBEDDING_PATH = SOURCE_FILES_PATH + 'embeddings/'\n",
    "\n",
    "PATH_TO_HYPERBOLIC_EMBEDDING = EMBEDDING_PATH + FILE_ID + '16_3_nickel.pth'\n",
    "\n",
    "\n",
    "PATH_TO_DISTRIBUTIONAL_EMBEDDING = EMBEDDING_PATH + FILE_ID + 'final_tree_type2vec_MTNCI'\n",
    "\n",
    "CONCEPT_EMBEDDING_PATHS = [PATH_TO_DISTRIBUTIONAL_EMBEDDING, \n",
    "                           PATH_TO_HYPERBOLIC_EMBEDDING]\n",
    "\n",
    "\n",
    "datasetManager = DatasetManager(FILE_ID)\n",
    "datasetManager.set_device(device)\n",
    "datasetManager.load_concept_embeddings(CONCEPT_EMBEDDING_PATHS = CONCEPT_EMBEDDING_PATHS, nickel = nickel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ...evaluating test predictions in distributional space... \n",
      "occurrence distributional\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "getting results for prediction 102760: 100%|██████████| 102760/102760 [16:49<00:00, 101.79it/s]\n",
      "Writing results for Occurrence Level in distributional space, top 1: 100%|██████████| 122/122 [00:00<00:00, 55565.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity distributional\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "getting results for prediction 1162: 100%|██████████| 1162/1162 [00:11<00:00, 102.76it/s]\n",
      "Writing results for Entity Level in distributional space, top 1: 100%|██████████| 118/118 [00:00<00:00, 50751.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concept1 distributional\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "getting results for prediction 122: 100%|██████████| 122/122 [00:01<00:00, 100.99it/s]\n",
      "Writing results for Concept Level (induce from occurrencies) in distributional space, top 1: 100%|██████████| 122/122 [00:00<00:00, 61157.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concept2 distributional\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "getting results for prediction 118: 100%|██████████| 118/118 [00:01<00:00, 99.83it/s]\n",
      "Writing results for Concept Level (induce from entities) in distributional space, top 1: 100%|██████████| 118/118 [00:00<00:00, 49334.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ...evaluating test predictions in hyperbolic space... \n",
      "occurrence hyperbolic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "getting results for prediction 102760: 100%|██████████| 102760/102760 [46:32<00:00, 36.80it/s]\n",
      "Writing results for Occurrence Level in hyperbolic space, top 1: 100%|██████████| 122/122 [00:00<00:00, 74300.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity hyperbolic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "getting results for prediction 1162: 100%|██████████| 1162/1162 [00:31<00:00, 36.79it/s]\n",
      "Writing results for Entity Level in hyperbolic space, top 1: 100%|██████████| 118/118 [00:00<00:00, 76840.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concept1 hyperbolic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "getting results for prediction 122: 100%|██████████| 122/122 [00:03<00:00, 36.87it/s]\n",
      "Writing results for Concept Level (induce from occurrencies) in hyperbolic space, top 1: 100%|██████████| 122/122 [00:00<00:00, 76948.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concept2 hyperbolic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "getting results for prediction 118: 100%|██████████| 118/118 [00:03<00:00, 36.90it/s]\n",
      "Writing results for Concept Level (induce from entities) in hyperbolic space, top 1: 100%|██████████| 118/118 [00:00<00:00, 56829.47it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "NAME = 'shimaoka_MTNCI_fair_sampled'\n",
    "\n",
    "results_path = 'results/excel_results/' + NAME + '.txt'\n",
    "TSV_path = 'results/excel_results/export_' + NAME + '.txt'\n",
    "\n",
    "model.set_results_paths(results_path = results_path, TSV_path = TSV_path)\n",
    "\n",
    "model.set_dataset_manager(datasetManager)\n",
    "\n",
    "topn = [1]\n",
    "\n",
    "model.type_prediction_on_test(topn, test_data, test_entities, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unk \n",
      "{'PublicTransitSystem', 'FictionalCharacter', 'Organisation', 'MilitaryUnit', 'River', 'MythologicalFigure', 'Arachnid', 'Fungus', 'Convention', 'Amphibian', 'Newspaper', 'Venue', 'VideoGame', 'ChemicalCompound', 'Species', 'City', 'Plant', 'Bird', 'EthnicGroup', 'Mollusca', 'Bridge', 'Drug', 'Crustacean', 'Surname', 'RadioStation', 'Animal', 'MilitaryStructure', 'Food', 'Fish', 'Holiday', 'Company', 'Village', 'Insect', 'Band', 'Settlement', 'Eukaryote', 'Mountain', 'Town', 'Film', 'Weapon', 'Island', 'Place', 'IceHockeyPlayer', 'Country', 'Mammal', 'Monarch', 'Website', 'Reptile'}\n",
      "unk unk \n",
      "{'Species', 'City', 'Crustacean', 'Arachnid', 'Writer', 'Scientist', 'HistoricPlace', 'Food', 'Amphibian', 'Politician', 'OfficeHolder', 'Actor', 'Mollusca'}\n",
      "unk springsit \n",
      "{'AdministrativeRegion', 'Place', 'Settlement'}\n",
      "unk meuse \n",
      "{'Lake', 'BodyOfWater'}\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "C_E = defaultdict(set)\n",
    "\n",
    "for entity, label in zip(test_entities, test_labels):\n",
    "    C_E[entity].add(label)\n",
    "    \n",
    "for k, v in C_E.items():\n",
    "    if len(v) > 1:\n",
    "        print(k)\n",
    "        print(v)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MTNCI_figet]",
   "language": "python",
   "name": "conda-env-MTNCI_figet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
