{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils import save_data_with_pickle, load_data_with_pickle\n",
    "from CorpusManager import CorpusManager\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read input corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:04<00:00, 20694.01it/s]\n"
     ]
    }
   ],
   "source": [
    "CORPUS_PATH = '/datahdd/vmanuel/ELMo/Corpora/shuffled_text_with_words'\n",
    "\n",
    "c = CorpusManager()\n",
    "c.read_corpus(CORPUS_PATH, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PICKLE_PATH = ('../../../source_files/pickles/')\n",
    "\n",
    "found_entity_dict = load_data_with_pickle(PICKLE_PATH + 'found_entity_dict_9_3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_entity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.joined_corpus[51634]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_indexes = load_data_with_pickle(PICKLE_PATH + 'word_occurrence_index_32150_100000static')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_indexes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "reverse_dict = defaultdict(list)\n",
    "\n",
    "entity_dict = load_data_with_pickle(PICKLE_PATH + 'entity_dict_9_3')\n",
    "\n",
    "for k, words in entity_dict.items():\n",
    "    for w in words:\n",
    "        reverse_dict[w].append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entities = []\n",
    "\n",
    "for k, v in entity_dict.items():\n",
    "    all_entities.extend(v)\n",
    "all_entities = set(all_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import Fore, Back, Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_entity_in_row(ENTITY, ROW, verbose):\n",
    "    \n",
    "    a = extract_rows_occurrency(ENTITY.split(' '), ROW)\n",
    "    if verbose:\n",
    "        print('row: {}'.format(ROW))\n",
    "        print('entity: {}'.format(ENTITY))\n",
    "        print('indexes of each word: {}'.format([(w, o) for w, o in zip(ENTITY.split(' '), a)]))\n",
    "        print(' '.join([Fore.BLACK + c_w if c_w not in ENTITY.split(' ') else Fore.RED + c_w for c_w in c.corpus[ROW]]))\n",
    "        print(Fore.BLACK + '--------')\n",
    "    values = []\n",
    "    for value in a[0]:\n",
    "        occ = [(value, 0)]\n",
    "        i = 1\n",
    "        while i < len(a) and value + i in a[i]:\n",
    "            occ.append(((value + i), i))\n",
    "            i += 1\n",
    "        if i == len(a):\n",
    "            if verbose:\n",
    "                print(Fore.BLACK + 'entity present in this sentence at the index {}'.format(value))\n",
    "            values.append(value)\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(Fore.BLACK + 'entity not present in this sentence at the index {}'.format(value))\n",
    "        if verbose:\n",
    "            print(Fore.BLACK + '--------')\n",
    "    if values:\n",
    "        return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "keys = set(word_indexes.keys())\n",
    "\n",
    "def extract_rows(word):\n",
    "    return [t[0] for t in word_indexes[word]] #extract the row index from each tuple\n",
    "\n",
    "def extract_rows_occurrency(word_phrase, row):\n",
    "    return [t[1] for s in word_phrase for t in word_indexes[s] if t[0] == row]\n",
    "\n",
    "j = 0\n",
    "verbose = False\n",
    "found = defaultdict(list)\n",
    "for entity in tqdm(all_entities):\n",
    "    splitted = entity.split(' ')\n",
    "    if set(splitted) <= keys:\n",
    "        # all words in this entity are in the corpus\n",
    "        i = 0\n",
    "        rows = extract_rows(splitted[i])\n",
    "        while rows and i + 1 < len(splitted):\n",
    "            i += 1\n",
    "            rows = [r for r in rows if r in extract_rows(splitted[i])]\n",
    "        if rows and len(splitted) > 1:\n",
    "            for r in rows:\n",
    "                b = check_entity_in_row(ENTITY=entity, ROW=r, verbose = verbose)\n",
    "            if b:\n",
    "                if verbose:\n",
    "                    print('entity found at index(es): {}'.format(' '.join([str(v) for v in b])))\n",
    "                found[entity].append((r, b))\n",
    "            j +=1\n",
    "        elif rows:\n",
    "            found[entity] = word_indexes[entity]\n",
    "print(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_occurrences = load_data_with_pickle(PICKLE_PATH + 'occurrences_of_entities')\n",
    "all_occurrences = [(k , v) if type(v[0]) == tuple else (k, v[0]) for k, v in all_occurrences.items() if len(k) > 2]\n",
    "all_occurrences = {x[0]: x[1] for x in all_occurrences}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_to_embed = [v[0] for values in all_occurrences.values() for v in values]\n",
    "\n",
    "print('total found entity mentions: {}'.format(len(sentences_to_embed)))\n",
    "print('fraction of sentences with entity mentions: {:.2f} ({} on {})'.format(len(set(sentences_to_embed))/len(c.joined_corpus),\n",
    "                                                                             len(set(sentences_to_embed)),\n",
    "                                                                             len(c.joined_corpus)))\n",
    "print('{:.2f} average entity mentions per sentence'.format(len(sentences_to_embed)/len(set(sentences_to_embed))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_occurrences['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_data_structure = {index:[] for index in sentences_to_embed if index < 10000}\n",
    "\n",
    "for entity_mention, occurrences in all_occurrences.items():\n",
    "    for couple in occurrences:\n",
    "        if couple[0] < 10000:\n",
    "            embedding_data_structure[couple[0]].append((couple[1], entity_mention))\n",
    "                    \n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "ordered_embedding_data_structure = OrderedDict(sorted(embedding_data_structure.items()))\n",
    "ordered_embedding_data_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.commands.elmo import ElmoEmbedder\n",
    "\n",
    "elmo = ElmoEmbedder(cuda_device = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_embedding_data_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "vectors_dict = defaultdict(list)\n",
    "\n",
    "for row_index, occurrences in tqdm(ordered_embedding_data_structure.items()):\n",
    "    vectors = elmo.embed_sentence(c.corpus[row_index])[2]\n",
    "    for occ in occurrences:\n",
    "        for word_index in occ[0]:\n",
    "            if len(occ[1].split(' ')) == 1:\n",
    "                vectors_dict[occ[1]].append(vectors[word_index])\n",
    "            else:\n",
    "                vecs = [vectors[w_i] for w_i in range(word_index, word_index + len(occ[1].split(' ')))]\n",
    "                vectors_dict[occ[1]].append(np.mean(vecs, axis = 0))                        \n",
    "# print('{}'.format('\\n'.join(['{}'.format((k, len(v))) for k, v in vectors_dict.items()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_entities = set(vectors_dict.keys())\n",
    "found_entity_dict = {k: set(v).intersection(found_entities) for k,v in entity_dict.items() if set(v).intersection(found_entities)}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_entity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = load_data_with_pickle(PICKLE_PATH + 'graph')\n",
    "\n",
    "found_entity_dict_2 = c.avoid_multilabeling(found_entity_dict, G, file = 'avoid_multilabeling.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_occurrences.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_entity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_dict = defaultdict(list)\n",
    "\n",
    "# entity_dict = load_data_with_pickle(PICKLE_PATH + 'entity_dict')\n",
    "\n",
    "for k, words in found_entity_dict.items():\n",
    "    for w in words:\n",
    "        reverse_dict[w].append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reverse_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_dict['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "entities = []\n",
    "\n",
    "for label, label_vectors in vectors_dict.items():\n",
    "    if label in reverse_dict:\n",
    "        for v in label_vectors:\n",
    "            X.append(v)\n",
    "            Y.append(reverse_dict[label])\n",
    "            entities.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data_with_pickle(PICKLE_PATH + '../vectors/elmo_vectors', X)\n",
    "save_data_with_pickle(PICKLE_PATH + '../vectors/labels', Y)\n",
    "save_data_with_pickle(PICKLE_PATH + '../vectors/entities', entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('MTNCI': conda)",
   "language": "python",
   "name": "python37664bitmtncicondad1aa09012c6f4676a7e50dc769fdaa25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
