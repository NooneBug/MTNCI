{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('./preprocessing/')\n",
    "from utils import load_data_with_pickle, save_data_with_pickle\n",
    "import numpy as np\n",
    "from DatasetManager import DatasetManager\n",
    "\n",
    "EMBEDDING_PATH = '../source_files/embeddings/'\n",
    "\n",
    "PATH_TO_HYPERBOLIC_EMBEDDING = EMBEDDING_PATH + '10_3_final_tree_HyperE_MTNCI'\n",
    "\n",
    "# PATH_TO_DISTRIBUTIONAL_EMBEDDING = EMBEDDING_PATH + '10_3_final_tree_type2vec_MTNCI'\n",
    "PATH_TO_DISTRIBUTIONAL_EMBEDDING = EMBEDDING_PATH + 'FEDE_type2vec'\n",
    "\n",
    "\n",
    "CONCEPT_EMBEDDING_PATHS = [PATH_TO_DISTRIBUTIONAL_EMBEDDING, PATH_TO_HYPERBOLIC_EMBEDDING]\n",
    "\n",
    "DATASET_PATH = '../source_files/vectors/'\n",
    "\n",
    "X_PATH = DATASET_PATH + 'X_10_3'\n",
    "Y_PATH = DATASET_PATH + 'Y_10_3'\n",
    "ENTITIES_PATH = DATASET_PATH + 'entities_10_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_embeddings = [load_data_with_pickle(x) for x in CONCEPT_EMBEDDING_PATHS]\n",
    "concept_embeddings = {'hyperbolic': concept_embeddings[1], \n",
    "                      'distributional':concept_embeddings[0]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmanuel/Notebooks/pytorch/MTNCI_pytorch/MTNCI_pytorch_env/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "concept_embeddings['distributional'] = {k: concept_embeddings['distributional'][k] for k in concept_embeddings['distributional'].wv.vocab}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_embeddings['hyperbolic'] = concept_embeddings['hyperbolic'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = load_data_with_pickle(X_PATH)\n",
    "Y = load_data_with_pickle(Y_PATH)\n",
    "entities = load_data_with_pickle(ENTITIES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilabel alerts: 38988\n",
      "Multilabel alerts: 0\n"
     ]
    }
   ],
   "source": [
    "from CorpusManager import CorpusManager\n",
    "\n",
    "c = CorpusManager()\n",
    "\n",
    "f_e_d = load_data_with_pickle('../source_files/pickles/10_3_found_entity_dict')\n",
    "tree = load_data_with_pickle('../source_files/pickles/10_3_final_tree')\n",
    "\n",
    "from collections import defaultdict\n",
    "reverse_dict = defaultdict(list)\n",
    "\n",
    "for k, words in f_e_d.items():\n",
    "    for w in words:\n",
    "        reverse_dict[w].append(k)\n",
    "\n",
    "found_entity_dict = c.avoid_multilabeling(f_e_d, tree, file = '../source_files/logs/avoid_multilabeling.txt')\n",
    "\n",
    "reverse_dict = defaultdict(list)\n",
    "\n",
    "for k, words in found_entity_dict.items():\n",
    "    for w in words:\n",
    "        reverse_dict[w].append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = [reverse_dict[e][0] for e in entities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1582474"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1582474"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1582474"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_present = []\n",
    "\n",
    "for label in list(set(Y)):\n",
    "#     for emb in concept_embeddings.values():\n",
    "    try:\n",
    "        a = concept_embeddings['distributional'][label]\n",
    "    except:\n",
    "        if label not in not_present:\n",
    "            not_present.append(label)\n",
    "len(not_present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [x for x, y in zip(X, Y) if y not in not_present]\n",
    "entities = [e for e, y in zip(entities, Y) if y not in not_present]\n",
    "Y = [y for y in Y if y not in not_present]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: 1174374, Y : 1174374, ENTITIES :1174374\n"
     ]
    }
   ],
   "source": [
    "print('X: {}, Y : {}, ENTITIES :{}'.format(len(X), len(Y), len(entities)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "339"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "class ciaone:\n",
    "    def split_data_by_unique_entities(self, X, Y, entities, exclude_min_threshold = 3):\n",
    "            self.unique_entities = list(set(entities))\n",
    "            self.direct_labeling = {e: y for e, y in zip(entities, Y)}\n",
    "            self.labels_of_unique_entities = [self.direct_labeling[e] for e in self.unique_entities]\n",
    "            \n",
    "            counter = Counter(self.labels_of_unique_entities)\n",
    "            \n",
    "            # exclude labels with less than 3 elements, these will not be useful\n",
    "            \n",
    "            self.filtered_entities = [e for e, l in zip(self.unique_entities, self.labels_of_unique_entities) if counter[l] >= exclude_min_threshold]\n",
    "            self.filtered_labels = [l for l in self.labels_of_unique_entities if counter[l] >= exclude_min_threshold]\n",
    "            self.filtered_out = [l for l in self.labels_of_unique_entities if counter[l] < exclude_min_threshold]\n",
    "            \n",
    "            self.filtered_out_len = len(set(self.filtered_out))\n",
    "            \n",
    "            print('{} labels filtered out based on exclude_min_threshold ({:.2f}% on dataset dimension)'.format(self.filtered_out_len,\n",
    "                                                                                               len(self.filtered_out)/len(self.labels_of_unique_entities)))\n",
    "            print('Initial labels: {}, current labels: {}'.format(len(set(self.labels_of_unique_entities)),\n",
    "                                                                  len(set(self.filtered_labels))))\n",
    "            self.entities_train, self.entities_test, \\\n",
    "                self.y_train_split, self.y_test_split = train_test_split(self.filtered_entities,\n",
    "                                                                         self.filtered_labels,\n",
    "                                                                         test_size = 0.1,\n",
    "                                                                         stratify = self.filtered_labels)\n",
    "            \n",
    "            self.entities_train, self.entities_val, \\\n",
    "                self.y_train, self.y_val = train_test_split(self.entities_train,\n",
    "                                                  self.y_train_split,\n",
    "                                                  test_size = 0.1,\n",
    "                                                  stratify = self.y_train_split)\n",
    "            \n",
    "            self.X_train = []\n",
    "            self.Y_train = []\n",
    "            self.E_train = []\n",
    "\n",
    "            self.X_val = []\n",
    "            self.Y_val = []\n",
    "            self.E_val = []\n",
    "\n",
    "            self.X_test = []\n",
    "            self.Y_test = []\n",
    "            self.E_test = []\n",
    "            \n",
    "            bar = tqdm(total = len(X))\n",
    "            filtered_set = set(self.filtered_entities)\n",
    "            for x, y, e in zip(X, Y, entities):\n",
    "                bar.update(1)\n",
    "                if e in filtered_set:\n",
    "                    if e in self.entities_train:\n",
    "                        self.X_train.append(x)\n",
    "                        self.Y_train.append(y)        \n",
    "                        self.E_train.append(e)\n",
    "\n",
    "                    elif e in self.entities_test:\n",
    "                        self.X_test.append(x)\n",
    "                        self.Y_test.append(y)\n",
    "                        self.E_test.append(e)\n",
    "\n",
    "                    elif e in self.entities_val:\n",
    "                        self.X_val.append(x)\n",
    "                        self.Y_val.append(y)\n",
    "                        self.E_val.append(e)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285 labels filtered out based on exclude_min_threshold (0.29% on dataset dimension)\n",
      "Initial labels: 339, current labels: 54\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42733f817e874fdfaa11a83bd302fafe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1174374.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c = ciaone()\n",
    "c.split_data_by_unique_entities(X, Y, entities, exclude_min_threshold = 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 698900, Val : 65728, Test :75157\n"
     ]
    }
   ],
   "source": [
    "print('Train: {}, Val : {}, Test :{}'.format(len(c.Y_train), len(c.Y_val), len(c.Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Train              |               Val               |              Test               \n",
      "---------------------------------|---------------------------------|---------------------------------\n",
      "          Place           143652 |          Place            16972  |          Place            15245  \n",
      "      Organisation        62910  |     TelevisionShow        8778   |         Person            5445   \n",
      "         Person           41863  |         Person            7619   |       MusicalWork         5078   \n",
      "       Settlement         38675  |          Event            3674   |         Protein           4925   \n",
      "         Country          26250  |         Company           3368   |       Automobile          4830   \n",
      "         Device           23349  |          Film             2019   |      Organisation         4072   \n",
      " ArchitecturalStructure   22887  |      Organisation         1945   |        Election           2986   \n",
      "       MusicalWork        22850  |         Protein           1854   |     TelevisionShow        2704   \n",
      "         Protein          22693  |          Award            1256   |         Company           2167   \n",
      "         Company          22645  |   AnatomicalStructure     1234   |      MilitaryUnit         1967   \n",
      "          Band            18134  |          Book             1156   |          Band             1864   \n",
      "         Species          16728  |          Band             1139   |         Disease           1851   \n",
      "   AnatomicalStructure    14098  |        Software           1080   |         Device            1778   \n",
      "          Food            12816  |         Species            943   |        Software           1642   \n",
      "        Software          12701  |      OfficeHolder          857   |        Language           1612   \n",
      "       WrittenWork        11540  |          Food              850   |        Building           1572   \n",
      "          Plant           11485  |        Mountain            839   |          Food             1442   \n",
      "          Book            11427  |         Disease            763   |          Book             1325   \n",
      "         Disease          10790  |         Device             621   |          Film             1183   \n",
      "   FictionalCharacter     10462  |      MilitaryUnit          607   |       WrittenWork         1079   \n",
      "        Building           9911  |        Building            539   |         Species            951   \n",
      "     PoliticalParty        9609  |    ChemicalCompound        520   |       EthnicGroup          903   \n",
      "        Language           9601  |      ProtectedArea         511   |   AnatomicalStructure      852   \n",
      "    ChemicalCompound       8717  |       MusicalWork          449   | ArchitecturalStructure     835   \n",
      "        Election           8530  |          Ship              425   |     PoliticalParty         779   \n",
      "       SportsEvent         7138  |         Country            406   |         Country            689   \n",
      "      MilitaryUnit         7092  |        Election            402   |    ChemicalCompound        610   \n",
      "        VideoGame          7020  |       Settlement           377   |          City              543   \n",
      "     TelevisionShow        7018  |       Automobile           358   |       Settlement           494   \n",
      "          Film             6655  |          City              350   |         Mammal             448   \n",
      "       RecordLabel         6336  |       SportsEvent          339   |          Ship              391   \n",
      "          Ship             6121  |         Mammal             332   |   FictionalCharacter       309   \n",
      "          City             5705  |         Athlete            285   |          Plant             282   \n",
      "         Mammal            4546  |   FictionalCharacter       256   |          Town              257   \n",
      "       Automobile          4308  |          Town              234   |         Athlete            227   \n",
      "         Athlete           4092  |          Plant             223   |         Artist             200   \n",
      "      SportsLeague         4031  |       EthnicGroup          219   |        VideoGame           200   \n",
      "          Event            3812  | ArchitecturalStructure     200   |         Village            192   \n",
      "       EthnicGroup         3463  |       WrittenWork          197   |      ProtectedArea         167   \n",
      "          Town             2574  |         Artist             186   |       SportsTeam           145   \n",
      "         Artist            2170  |         Village            173   |          Event             99    \n",
      "         Village           1831  |        Scientist           146   |          Award             86    \n",
      "         Island            1622  |         Animal             143   |          Fish              82    \n",
      "       SportsTeam          1381  |        VideoGame           139   |      OfficeHolder          79    \n",
      "         Animal            1198  |        Language            134   |         Writer             78    \n",
      "          Award            1111  |       SportsTeam           125   |         Island             76    \n",
      "        Mountain           1058  |     PoliticalParty         93    | EducationalInstitution     75    \n",
      "      OfficeHolder         855   |         Writer             72    |        Scientist           63    \n",
      " EducationalInstitution    678   |         Island             72    |       Politician           58    \n",
      "         Writer            673   | EducationalInstitution     70    |         Animal             50    \n",
      "      ProtectedArea        654   |       Politician           54    |       SportsEvent          47    \n",
      "        Scientist          573   |          Fish              44    |      SportsLeague          45    \n",
      "       Politician          478   |      SportsLeague          41    |        Mountain            40    \n",
      "          Fish             384   |       RecordLabel          40    |       RecordLabel          38    \n"
     ]
    }
   ],
   "source": [
    "Tr = Counter(c.Y_train).most_common()\n",
    "Va = Counter(c.Y_val).most_common()\n",
    "Te = Counter(c.Y_test).most_common()\n",
    "\n",
    "print('{:^33}|{:^33}|{:^33}'.format('Train','Val', 'Test'))\n",
    "print('{:-^33}|{:-^33}|{:-^33}'.format('', '', ''))\n",
    "\n",
    "for x, y, z in zip(Tr, Va, Te):\n",
    "    print('{:^25}{:^8}|{:^25}{:^9}|{:^25}{:^9}'.format(x[0], x[1], y[0], y[1], z[0], z[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def shuffle_dataset(X, Y, E):\n",
    "    random.seed(236451)\n",
    "    A = [[x, y, e] for x, y, e in zip(X, Y, E)]\n",
    "    random.shuffle(A)\n",
    "    return [x[0] for x in A], [x[1] for x in A], [x[2] for x in A]\n",
    "\n",
    "c.X_train, c.Y_train, c.E_train = shuffle_dataset(c.X_train, c.Y_train, c.E_train)\n",
    "\n",
    "c.X_test, c.Y_test, c.E_test = shuffle_dataset(c.X_test, c.Y_test, c.E_test)\n",
    "\n",
    "c.X_val, c.Y_val, c.E_val = shuffle_dataset(c.X_val, c.Y_val, c.E_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 698900, Val : 65728, Test :75157\n"
     ]
    }
   ],
   "source": [
    "print('Train: {}, Val : {}, Test :{}'.format(len(c.Y_train), len(c.Y_val), len(c.Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PICKLE_PATH = 'datasets/'\n",
    "\n",
    "ID = '_10_4_300'\n",
    "\n",
    "save_data_with_pickle(PICKLE_PATH + 'filtered_X_train' + ID, c.X_train)\n",
    "save_data_with_pickle(PICKLE_PATH + 'filtered_X_val' + ID, c.X_val)\n",
    "save_data_with_pickle(PICKLE_PATH + 'filtered_X_test' + ID, c.X_test)\n",
    "\n",
    "save_data_with_pickle(PICKLE_PATH + 'filtered_Y_train' + ID, c.Y_train)\n",
    "save_data_with_pickle(PICKLE_PATH + 'filtered_Y_val' + ID, c.Y_val)\n",
    "save_data_with_pickle(PICKLE_PATH + 'filtered_Y_test' + ID, c.Y_test)\n",
    "\n",
    "save_data_with_pickle(PICKLE_PATH + 'filtered_entities_train' + ID, c.E_train)\n",
    "save_data_with_pickle(PICKLE_PATH + 'filtered_entities_val' + ID, c.E_val)\n",
    "save_data_with_pickle(PICKLE_PATH + 'filtered_entities_test' + ID, c.E_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_numeric_label(labels):\n",
    "    return [numeric_label_map[y] for y in labels]\n",
    "\n",
    "numeric_label_map = {y: x for x, y in enumerate(set(c.Y_train))}\n",
    "inverse_numeric_label_map = {v:k for k,v in numeric_label_map.items()}\n",
    "\n",
    "len(numeric_label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.y_numeric_train = get_numeric_label(c.Y_train)\n",
    "c.y_numeric_test = get_numeric_label(c.Y_test)\n",
    "c.y_numeric_val = get_numeric_label(c.Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create dataset for deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_explicit_dataset(y_train, y_test, y_val, embeddings):\n",
    "\n",
    "    explicit_y_train = {k:[] for k in embeddings.keys()}\n",
    "    explicit_y_test = {k:[] for k in embeddings.keys()}\n",
    "    explicit_y_val = {k:[] for k in embeddings.keys()}\n",
    "\n",
    "    for label in y_train:\n",
    "        for k, emb in embeddings.items():\n",
    "            explicit_y_train[k].append(emb[label])\n",
    "    \n",
    "    for label in y_test:\n",
    "        for k, emb in embeddings.items():\n",
    "            explicit_y_test[k].append(emb[label])\n",
    "\n",
    "    for label in y_val:\n",
    "        for k, emb in embeddings.items():\n",
    "            explicit_y_val[k].append(emb[label])\n",
    "    \n",
    "    \n",
    "    for k, dataSET in explicit_y_train.items():\n",
    "        explicit_y_train[k] = np.array(dataSET)\n",
    "    \n",
    "    for k, dataSET in explicit_y_test.items():\n",
    "        explicit_y_test[k] = np.array(dataSET)\n",
    "    \n",
    "    for k, dataSET in explicit_y_val.items():\n",
    "        explicit_y_val[k] = np.array(dataSET)\n",
    "        \n",
    "    return explicit_y_train, explicit_y_test, explicit_y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "explicit_y_train, explicit_y_test, explicit_y_val = create_explicit_dataset(c.Y_train, c.Y_test, c.Y_val, concept_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, vector_list, label_list, target_list):\n",
    "        self.X = torch.tensor(vector_list, device = device)\n",
    "        self.labels = torch.tensor(label_list, device = device)\n",
    "        self.target_list = {k: torch.tensor(x, dtype = torch.float64, device = device) for k, x in target_list.items()}\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.X[index], \n",
    "                self.labels[index],\n",
    "                {k:x[index] for k, x in target_list}\n",
    "               )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = MyDataset(c.X_train, \n",
    "                     c.y_numeric_train, \n",
    "                     explicit_y_train) \n",
    "trainloader = DataLoader(trainset, batch_size=65536, shuffle=True)\n",
    "\n",
    "testset = MyDataset(c.X_test,\n",
    "                    c.y_numeric_test,\n",
    "                    explicit_y_test) \n",
    "testloader = DataLoader(testset, batch_size=4096, shuffle=False)\n",
    "\n",
    "valset = MyDataset(c.X_val, \n",
    "                   c.y_numeric_val, \n",
    "                   explicit_y_val)\n",
    "valloader = DataLoader(valset, batch_size=4096, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_loss(true, pred):\n",
    "    cossim = torch.nn.CosineSimilarity(dim = 1)\n",
    "    return 1 - cossim(true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperbolic_loss(y_pred, y_true, regul):\n",
    "\n",
    "    numerator = 2 * torch.norm(y_true - y_pred, dim = 1)**2\n",
    "\n",
    "    pred_norm = torch.norm(y_pred, dim = 1)**2\n",
    "    true_norm = torch.norm(y_true, dim = 1)**2\n",
    "\n",
    "    left_denom = 1 - pred_norm\n",
    "    right_denom = 1 - true_norm\n",
    "    \n",
    "#     left_denom = torch.where(left_denom <= 0, torch.tensor(1e-5), left_denom)\n",
    "    \n",
    "    denom = left_denom * right_denom\n",
    "\n",
    "    frac = numerator/denom\n",
    "    acos = acosh(1  + frac)\n",
    "    \n",
    "    \n",
    "    l0 = torch.tensor(1., device = device)\n",
    "    l1 = torch.tensor(1., device = device)\n",
    "    \n",
    "    if sum(regul) > 1:\n",
    "        \n",
    "#         regularization = torch.nn.modules.distance.PairwiseDistance()(y_pred, y_true)\n",
    "        \n",
    "#         regularization = torch.sqrt(numerator/2)\n",
    "        \n",
    "        true_perm = y_true[torch.randperm(y_true.size()[0])]\n",
    "        \n",
    "        l0 = torch.abs(hyperbolic_loss(y_pred, true_perm, regul=[0, 0, 1])[0] - hyperbolic_loss(y_true, true_perm, regul = [0, 0, 1])[0])\n",
    "        l1 = mse(y_pred, y_true, 0)\n",
    "    \n",
    "    return acos**regul[2] + l0 * regul[0] + l1 * regul[1], l0 * regul[0] + l1 * regul[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class CommonLayer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_d,\n",
    "                 dims = None,\n",
    "                 dropout_prob = 0):\n",
    "        super().__init__()\n",
    "        \n",
    "        prec = input_d\n",
    "        self.fully = nn.ModuleList()\n",
    "        self.bns = nn.ModuleList()\n",
    "\n",
    "        for dim in dims:\n",
    "            self.fully.append(nn.Linear(prec, dim).cuda())\n",
    "            self.bns.append(nn.BatchNorm1d(dim).cuda())\n",
    "            prec = dim            \n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout_prob).cuda()\n",
    "        self.leaky_relu = nn.LeakyReLU(0.1).cuda()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.fully)):\n",
    "            x = x.double()\n",
    "            x = self.dropout(self.bns[i](self.leaky_relu(self.fully[i](x))))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class RegressionOutput(nn.Module):\n",
    "    def __init__(self, hidden_dim, dims, manifold):\n",
    "        super().__init__()\n",
    "        self.out = nn.ModuleList()\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.1).cuda()\n",
    "        self.leaky_relu = nn.ReLU().cuda()\n",
    "        self.bns = nn.ModuleList()\n",
    "        \n",
    "        prec = hidden_dim\n",
    "        \n",
    "        for dim in dims:\n",
    "            if mode == 'poincare':\n",
    "                self.out.append(MobiusLinear(prec, dim).cuda())\n",
    "            elif mode == 'euclid':\n",
    "                self.out.append(nn.Linear(prec, dim).cuda())\n",
    "            else:\n",
    "                print('ERROR: NO MODE SELECTED')\n",
    "                \n",
    "            self.bns.append(nn.BatchNorm1d(dim).cuda())\n",
    "            prec = dim\n",
    "            \n",
    "    def forward(self, x):\n",
    "#         x = x.double()\n",
    "        for i in range(len(self.out) - 1):\n",
    "            x = self.leaky_relu(self.out[i](x))\n",
    "        out = self.out[-1](x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTN(nn.Module):    \n",
    "    def __init__(self,\n",
    "                 input_d, \n",
    "                 dims = None,\n",
    "                 out_spec = [{'manifold':'euclid', 'dim':10},\n",
    "                             {'manifold':'poincare', 'dim':2}]\n",
    "                 dropout_prob = 0.2):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.common_network = CommonLayer(input_d=input_d,\n",
    "                                          dims = dims,\n",
    "                                          dropout_prob=dropout_prob)\n",
    "        \n",
    "        self.out_layers = nn.ModuleList()\n",
    "        \n",
    "        for spec in out_spec:\n",
    "            self.out_layers.append(RegressionOutput(hidden_dim=dims[-1],\n",
    "                                              dims=spec['dim'],\n",
    "                                              manifold = spec['manifold']))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.common_network(x)\n",
    "        \n",
    "        outDis = self.dis_out_layer(x)\n",
    "        outHyp = self.hyp_out_layer(x)\n",
    "        \n",
    "        return outDis, outHyp    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MTNCI_pytorch_kernel",
   "language": "python",
   "name": "mtnci_pytorch_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
