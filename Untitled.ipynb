{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('./preprocessing/')\n",
    "from utils import load_data_with_pickle, save_data_with_pickle\n",
    "import numpy as np\n",
    "from DatasetManager import DatasetManager\n",
    "\n",
    "EMBEDDING_PATH = '../source_files/embeddings/'\n",
    "\n",
    "PATH_TO_HYPERBOLIC_EMBEDDING = EMBEDDING_PATH + '10_3_final_tree_HyperE_MTNCI'\n",
    "\n",
    "# PATH_TO_DISTRIBUTIONAL_EMBEDDING = EMBEDDING_PATH + '10_3_final_tree_type2vec_MTNCI'\n",
    "PATH_TO_DISTRIBUTIONAL_EMBEDDING = EMBEDDING_PATH + 'FEDE_type2vec'\n",
    "\n",
    "\n",
    "CONCEPT_EMBEDDING_PATHS = [PATH_TO_DISTRIBUTIONAL_EMBEDDING, PATH_TO_HYPERBOLIC_EMBEDDING]\n",
    "\n",
    "DATASET_PATH = '../source_files/vectors/'\n",
    "\n",
    "X_PATH = DATASET_PATH + 'X_10_3'\n",
    "Y_PATH = DATASET_PATH + 'Y_10_3'\n",
    "ENTITIES_PATH = DATASET_PATH + 'entities_10_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_embeddings = [load_data_with_pickle(x) for x in CONCEPT_EMBEDDING_PATHS]\n",
    "concept_embeddings = {'hyperbolic': concept_embeddings[1], \n",
    "                      'distributional':concept_embeddings[0]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmanuel/Notebooks/pytorch/MTNCI_pytorch/MTNCI_pytorch_env/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "concept_embeddings['distributional'] = {k: concept_embeddings['distributional'][k] for k in concept_embeddings['distributional'].wv.vocab}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_embeddings['hyperbolic'] = concept_embeddings['hyperbolic'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = load_data_with_pickle(X_PATH)\n",
    "Y = load_data_with_pickle(Y_PATH)\n",
    "entities = load_data_with_pickle(ENTITIES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilabel alerts: 38988\n",
      "Multilabel alerts: 0\n"
     ]
    }
   ],
   "source": [
    "from CorpusManager import CorpusManager\n",
    "\n",
    "c = CorpusManager()\n",
    "\n",
    "f_e_d = load_data_with_pickle('../source_files/pickles/10_3_found_entity_dict')\n",
    "tree = load_data_with_pickle('../source_files/pickles/10_3_final_tree')\n",
    "\n",
    "from collections import defaultdict\n",
    "reverse_dict = defaultdict(list)\n",
    "\n",
    "for k, words in f_e_d.items():\n",
    "    for w in words:\n",
    "        reverse_dict[w].append(k)\n",
    "\n",
    "found_entity_dict = c.avoid_multilabeling(f_e_d, tree, file = '../source_files/logs/avoid_multilabeling.txt')\n",
    "\n",
    "reverse_dict = defaultdict(list)\n",
    "\n",
    "for k, words in found_entity_dict.items():\n",
    "    for w in words:\n",
    "        reverse_dict[w].append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = [reverse_dict[e][0] for e in entities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1582474"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1582474"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1582474"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_present = []\n",
    "\n",
    "for label in list(set(Y)):\n",
    "#     for emb in concept_embeddings.values():\n",
    "    try:\n",
    "        a = concept_embeddings['distributional'][label]\n",
    "    except:\n",
    "        if label not in not_present:\n",
    "            not_present.append(label)\n",
    "len(not_present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [x for x, y in zip(X, Y) if y not in not_present]\n",
    "entities = [e for e, y in zip(entities, Y) if y not in not_present]\n",
    "Y = [y for y in Y if y not in not_present]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: 1168730, Y : 1168730, ENTITIES :1168730\n"
     ]
    }
   ],
   "source": [
    "print('X: {}, Y : {}, ENTITIES :{}'.format(len(X), len(Y), len(entities)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "339"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "class ciaone:\n",
    "    def split_data_by_unique_entities(self, X, Y, entities, exclude_min_threshold = 3):\n",
    "            self.unique_entities = list(set(entities))\n",
    "            self.direct_labeling = {e: y for e, y in zip(entities, Y)}\n",
    "            self.labels_of_unique_entities = [self.direct_labeling[e] for e in self.unique_entities]\n",
    "            \n",
    "            counter = Counter(self.labels_of_unique_entities)\n",
    "            \n",
    "            # exclude labels with less than 3 elements, these will not be useful\n",
    "            \n",
    "            self.filtered_entities = [e for e, l in zip(self.unique_entities, self.labels_of_unique_entities) if counter[l] >= exclude_min_threshold]\n",
    "            self.filtered_labels = [l for l in self.labels_of_unique_entities if counter[l] >= exclude_min_threshold]\n",
    "            self.filtered_out = [l for l in self.labels_of_unique_entities if counter[l] < exclude_min_threshold]\n",
    "            \n",
    "            self.filtered_out_len = len(set(self.filtered_out))\n",
    "            \n",
    "            print('{} labels filtered out based on exclude_min_threshold ({:.2f}% on dataset dimension)'.format(self.filtered_out_len,\n",
    "                                                                                               len(self.filtered_out)/len(self.labels_of_unique_entities)))\n",
    "            print('Initial labels: {}, current labels: {}'.format(len(set(self.labels_of_unique_entities)),\n",
    "                                                                  len(set(self.filtered_labels))))\n",
    "            self.entities_train, self.entities_test, \\\n",
    "                self.y_train_split, self.y_test_split = train_test_split(self.filtered_entities,\n",
    "                                                                         self.filtered_labels,\n",
    "                                                                         test_size = 0.1,\n",
    "                                                                         stratify = self.filtered_labels)\n",
    "            \n",
    "            self.entities_train, self.entities_val, \\\n",
    "                self.y_train, self.y_val = train_test_split(self.entities_train,\n",
    "                                                  self.y_train_split,\n",
    "                                                  test_size = 0.1,\n",
    "                                                  stratify = self.y_train_split)\n",
    "            \n",
    "            self.X_train = []\n",
    "            self.Y_train = []\n",
    "            self.E_train = []\n",
    "\n",
    "            self.X_val = []\n",
    "            self.Y_val = []\n",
    "            self.E_val = []\n",
    "\n",
    "            self.X_test = []\n",
    "            self.Y_test = []\n",
    "            self.E_test = []\n",
    "            \n",
    "            bar = tqdm(total = len(X))\n",
    "            filtered_set = set(self.filtered_entities)\n",
    "            for x, y, e in zip(X, Y, entities):\n",
    "                bar.update(1)\n",
    "                if e in filtered_set:\n",
    "                    if e in self.entities_train:\n",
    "                        self.X_train.append(x)\n",
    "                        self.Y_train.append(y)        \n",
    "                        self.E_train.append(e)\n",
    "\n",
    "                    elif e in self.entities_test:\n",
    "                        self.X_test.append(x)\n",
    "                        self.Y_test.append(y)\n",
    "                        self.E_test.append(e)\n",
    "\n",
    "                    elif e in self.entities_val:\n",
    "                        self.X_val.append(x)\n",
    "                        self.Y_val.append(y)\n",
    "                        self.E_val.append(e)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285 labels filtered out based on exclude_min_threshold (0.29% on dataset dimension)\n",
      "Initial labels: 339, current labels: 54\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11cec15de09341b6b5b8a1ce818344d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1168730.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c = ciaone()\n",
    "c.split_data_by_unique_entities(X, Y, entities, exclude_min_threshold = 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train: {}, Val : {}, Test :{}'.format(len(c.Y_train), len(c.Y_val), len(c.Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def shuffle_dataset_and_sample(X, Y, E, fraction = 1):\n",
    "    random.seed(236451)\n",
    "    frac = int(len(X) * fraction) \n",
    "    A = [[x, y, e] for x, y, e in zip(X, Y, E)]\n",
    "    random.shuffle(A)\n",
    "    return [x[0] for i, x in enumerate(A) if i < frac], [x[1] for i, x in enumerate(A) if i < frac], [x[2] for i, x in enumerate(A) if i < frac]\n",
    "\n",
    "c.X_train, c.Y_train, c.E_train = shuffle_dataset_and_sample(c.X_train, c.Y_train, c.E_train, 0.10)\n",
    "\n",
    "c.X_test, c.Y_test, c.E_test = shuffle_dataset_and_sample(c.X_test, c.Y_test, c.E_test, 0.10)\n",
    "\n",
    "c.X_val, c.Y_val, c.E_val = shuffle_dataset_and_sample(c.X_val, c.Y_val, c.E_val, 0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Tr = Counter(c.Y_train).most_common()\n",
    "Va = Counter(c.Y_val).most_common()\n",
    "Te = Counter(c.Y_test).most_common()\n",
    "\n",
    "print('{:^33}|{:^33}|{:^33}'.format('Train','Val', 'Test'))\n",
    "print('{:-^33}|{:-^33}|{:-^33}'.format('', '', ''))\n",
    "\n",
    "for x, y, z in zip(Tr, Va, Te):\n",
    "    print('{:^25}{:^8}|{:^25}{:^9}|{:^25}{:^9}'.format(x[0], x[1], y[0], y[1], z[0], z[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train: {}, Val : {}, Test :{}'.format(len(c.Y_train), len(c.Y_val), len(c.Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PICKLE_PATH = 'datasets/'\n",
    "\n",
    "ID = '_10_4_300_0.1'\n",
    "\n",
    "save_data_with_pickle(PICKLE_PATH + 'filtered_X_train' + ID, c.X_train)\n",
    "save_data_with_pickle(PICKLE_PATH + 'filtered_X_val' + ID, c.X_val)\n",
    "save_data_with_pickle(PICKLE_PATH + 'filtered_X_test' + ID, c.X_test)\n",
    "\n",
    "save_data_with_pickle(PICKLE_PATH + 'filtered_Y_train' + ID, c.Y_train)\n",
    "save_data_with_pickle(PICKLE_PATH + 'filtered_Y_val' + ID, c.Y_val)\n",
    "save_data_with_pickle(PICKLE_PATH + 'filtered_Y_test' + ID, c.Y_test)\n",
    "\n",
    "save_data_with_pickle(PICKLE_PATH + 'filtered_entities_train' + ID, c.E_train)\n",
    "save_data_with_pickle(PICKLE_PATH + 'filtered_entities_val' + ID, c.E_val)\n",
    "save_data_with_pickle(PICKLE_PATH + 'filtered_entities_test' + ID, c.E_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_numeric_label(labels):\n",
    "    return [numeric_label_map[y] for y in labels]\n",
    "\n",
    "numeric_label_map = {y: x for x, y in enumerate(set(c.Y_train))}\n",
    "inverse_numeric_label_map = {v:k for k,v in numeric_label_map.items()}\n",
    "\n",
    "len(numeric_label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.y_numeric_train = get_numeric_label(c.Y_train)\n",
    "c.y_numeric_test = get_numeric_label(c.Y_test)\n",
    "c.y_numeric_val = get_numeric_label(c.Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create dataset for deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_explicit_dataset(y_train, y_test, y_val, embeddings):\n",
    "\n",
    "    explicit_y_train = {k:[] for k in embeddings.keys()}\n",
    "    explicit_y_test = {k:[] for k in embeddings.keys()}\n",
    "    explicit_y_val = {k:[] for k in embeddings.keys()}\n",
    "\n",
    "    for label in y_train:\n",
    "        for k, emb in embeddings.items():\n",
    "            explicit_y_train[k].append(emb[label])\n",
    "    \n",
    "    for label in y_test:\n",
    "        for k, emb in embeddings.items():\n",
    "            explicit_y_test[k].append(emb[label])\n",
    "\n",
    "    for label in y_val:\n",
    "        for k, emb in embeddings.items():\n",
    "            explicit_y_val[k].append(emb[label])\n",
    "    \n",
    "    \n",
    "    for k, dataSET in explicit_y_train.items():\n",
    "        explicit_y_train[k] = np.array(dataSET)\n",
    "    \n",
    "    for k, dataSET in explicit_y_test.items():\n",
    "        explicit_y_test[k] = np.array(dataSET)\n",
    "    \n",
    "    for k, dataSET in explicit_y_val.items():\n",
    "        explicit_y_val[k] = np.array(dataSET)\n",
    "        \n",
    "    return explicit_y_train, explicit_y_test, explicit_y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "explicit_y_train, explicit_y_test, explicit_y_val = create_explicit_dataset(c.Y_train, c.Y_test, c.Y_val, concept_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, vector_list, label_list, target_list):\n",
    "        self.X = torch.tensor(vector_list, device = device)\n",
    "        self.labels = torch.tensor(label_list, device = device)\n",
    "        self.target_list = {k: torch.tensor(x, dtype = torch.float64, device = device) for k, x in target_list.items()}\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.X[index], \n",
    "                self.labels[index],\n",
    "                {k:x[index] for k, x in self.target_list.items()}\n",
    "               )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = MyDataset(c.X_train, \n",
    "                     c.y_numeric_train, \n",
    "                     explicit_y_train) \n",
    "trainloader = DataLoader(trainset, batch_size=4096, shuffle=True)\n",
    "\n",
    "testset = MyDataset(c.X_test,\n",
    "                    c.y_numeric_test,\n",
    "                    explicit_y_test) \n",
    "testloader = DataLoader(testset, batch_size=4096, shuffle=False)\n",
    "\n",
    "valset = MyDataset(c.X_val, \n",
    "                   c.y_numeric_val, \n",
    "                   explicit_y_val)\n",
    "valloader = DataLoader(valset, batch_size=4096, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_losses(epoch, epochs, epochs_no_improve, n_epochs_stop, loss, val_loss, sim, colored, val_colored, sim_colored, norms, time):\n",
    "    print(Fore.WHITE + \"Epoch: {:>2}/{}..\".format(epoch+1, epochs))\n",
    "    \n",
    "    names = ['Distributional', 'Hyperbolic']\n",
    "    \n",
    "    print(Fore.WHITE + \"{}{:>14} {:>12} \".format(names[0], \n",
    "                                                    ' Training Loss:', Fore.GREEN + str(round(loss[0], 5)) if colored[0] \n",
    "                                                    else Fore.WHITE + str(round(loss[0], 5))),\n",
    "          Fore.WHITE + \"{}{:>9} {:>12} \".format(names[0], ' Val Loss:', Fore.GREEN + str(round(val_loss[0], 5)) if val_colored[0] \n",
    "                                                    else Fore.WHITE + str(round(val_loss[0], 5))),\n",
    "          Fore.WHITE + \"{}{:>14} {:>12} \".format(names[1], \n",
    "                                                    ' Training Loss:', Fore.GREEN + str(round(loss[1], 5)) if colored[1] \n",
    "                                                    else Fore.WHITE + str(round(loss[1], 5))),\n",
    "          Fore.WHITE + \"{}{:>9} {:>12} \\n\".format(names[1], ' Val Loss:', Fore.GREEN + str(round(val_loss[1], 5)) if val_colored[1] \n",
    "                                                    else Fore.WHITE + str(round(val_loss[1], 5))),\n",
    "          Fore.WHITE + \"Mean Similarities: {:>16} \".format(Fore.GREEN + str(round(sim[0], 4)) if sim_colored[0]\n",
    "                                                           else Fore.WHITE + str(round(sim[0], 4))),\n",
    "          Fore.WHITE + \"{:>16}\".format(Fore.GREEN + str(round(sim[1], 4)) if sim_colored[1]\n",
    "                                        else Fore.WHITE + str(round(sim[1], 4))),\n",
    "          Fore.WHITE + \"  Val Loss: {:>16} \".format(Fore.GREEN + str(round(val_loss[2], 5)) if val_colored[2]\n",
    "                                                           else Fore.WHITE + str(round(val_loss[2], 5))),\n",
    "          Fore.WHITE + \" Epochs from last best: {}/{}\".format(epochs_no_improve, n_epochs_stop),\n",
    "          Fore.WHITE + \"Mean Norm: {}\".format(round(norms, 5)),\n",
    "          Fore.WHITE + \"Epoch Time : {}\".format(round(time, 4))\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_loss(true, pred):\n",
    "    cossim = torch.nn.CosineSimilarity(dim = 1)\n",
    "    return 1 - cossim(true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperbolic_loss(y_pred, y_true, regul):\n",
    "\n",
    "    numerator = 2 * torch.norm(y_true - y_pred, dim = 1)**2\n",
    "\n",
    "    pred_norm = torch.norm(y_pred, dim = 1)**2\n",
    "    true_norm = torch.norm(y_true, dim = 1)**2\n",
    "\n",
    "    left_denom = 1 - pred_norm\n",
    "    right_denom = 1 - true_norm\n",
    "    \n",
    "#     left_denom = torch.where(left_denom <= 0, torch.tensor(1e-5), left_denom)\n",
    "    \n",
    "    denom = left_denom * right_denom\n",
    "\n",
    "    frac = numerator/denom\n",
    "    acos = acosh(1  + frac)\n",
    "    \n",
    "    \n",
    "    l0 = torch.tensor(1., device = device)\n",
    "    l1 = torch.tensor(1., device = device)\n",
    "    \n",
    "    if sum(regul) > 1:\n",
    "        \n",
    "#         regularization = torch.nn.modules.distance.PairwiseDistance()(y_pred, y_true)\n",
    "        \n",
    "#         regularization = torch.sqrt(numerator/2)\n",
    "        \n",
    "        true_perm = y_true[torch.randperm(y_true.size()[0])]\n",
    "        \n",
    "        l0 = torch.abs(hyperbolic_loss(y_pred, true_perm, regul=[0, 0, 1])[0] - hyperbolic_loss(y_true, true_perm, regul = [0, 0, 1])[0])\n",
    "        l1 = mse(y_pred, y_true, 0)\n",
    "    \n",
    "    return acos**regul[2] + l0 * regul[0] + l1 * regul[1], l0 * regul[0] + l1 * regul[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geoopt\n",
    "class MobiusLinear(torch.nn.Linear):\n",
    "    def __init__(self, *args, nonlin=None, ball=None, c=1.0, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # for manifolds that have parameters like Poincare Ball\n",
    "        # we have to attach them to the closure Module.\n",
    "        # It is hard to implement device allocation for manifolds in other case.\n",
    "        self.ball = create_ball(ball, c)\n",
    "        if self.bias is not None:\n",
    "            self.bias = geoopt.ManifoldParameter(self.bias, manifold=self.ball)\n",
    "        self.nonlin = nonlin\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return mobius_linear(\n",
    "            input,\n",
    "            weight=self.weight,\n",
    "            bias=self.bias,\n",
    "            nonlin=self.nonlin,\n",
    "            ball=self.ball,\n",
    "        )\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.eye_(self.weight)\n",
    "        self.weight.add_(torch.rand_like(self.weight).mul_(1e-3))\n",
    "        if self.bias is not None:\n",
    "            self.bias.zero_()\n",
    "\n",
    "\n",
    "# package.nn.functional.py\n",
    "def mobius_linear(input, weight, bias=None, nonlin=None, *, ball: geoopt.PoincareBall):\n",
    "    output = ball.mobius_matvec(weight, input)\n",
    "    if bias is not None:\n",
    "        output = ball.mobius_add(output, bias)\n",
    "    if nonlin is not None:\n",
    "        output = ball.logmap0(output)\n",
    "        output = nonlin(output)\n",
    "        output = ball.expmap0(output)\n",
    "    return output\n",
    "\n",
    "def create_ball(ball=None, c=None):\n",
    "    \"\"\"\n",
    "    Helper to create a PoincareBall.\n",
    "    Sometimes you may want to share a manifold across layers, e.g. you are using scaled PoincareBall.\n",
    "    In this case you will require same curvature parameters for different layers or end up with nans.\n",
    "    Parameters\n",
    "    ----------\n",
    "    ball : geoopt.PoincareBall\n",
    "    c : float\n",
    "    Returns\n",
    "    -------\n",
    "    geoopt.PoincareBall\n",
    "    \"\"\"\n",
    "    if ball is None:\n",
    "        assert c is not None, \"curvature of the ball should be explicitly specified\"\n",
    "        ball = geoopt.PoincareBall(c)\n",
    "    # else trust input\n",
    "    return ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class CommonLayer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_d,\n",
    "                 dims = None,\n",
    "                 dropout_prob = 0):\n",
    "        super().__init__()\n",
    "        \n",
    "        prec = input_d\n",
    "        self.fully = nn.ModuleList()\n",
    "        self.bns = nn.ModuleList()\n",
    "\n",
    "        for dim in dims:\n",
    "            self.fully.append(nn.Linear(prec, dim).cuda())\n",
    "            self.bns.append(nn.BatchNorm1d(dim).cuda())\n",
    "            prec = dim            \n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout_prob).cuda()\n",
    "        self.leaky_relu = nn.LeakyReLU(0.1).cuda()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.fully)):\n",
    "            x = x.double()\n",
    "            x = self.dropout(self.bns[i](self.leaky_relu(self.fully[i](x))))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class RegressionOutput(nn.Module):\n",
    "    def __init__(self, hidden_dim, dims, manifold):\n",
    "        super().__init__()\n",
    "        self.out = nn.ModuleList()\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.1).cuda()\n",
    "        self.leaky_relu = nn.ReLU().cuda()\n",
    "        self.bns = nn.ModuleList()\n",
    "        \n",
    "        prec = hidden_dim\n",
    "        \n",
    "        for dim in dims:\n",
    "            if manifold == 'poincare':\n",
    "                self.out.append(MobiusLinear(prec, dim).cuda())\n",
    "            elif manifold == 'euclid':\n",
    "                self.out.append(nn.Linear(prec, dim).cuda())\n",
    "            else:\n",
    "                print('ERROR: NO MODE SELECTED')\n",
    "                \n",
    "            self.bns.append(nn.BatchNorm1d(dim).cuda())\n",
    "            prec = dim\n",
    "            \n",
    "    def forward(self, x):\n",
    "#         x = x.double()\n",
    "        for i in range(len(self.out) - 1):\n",
    "            x = self.leaky_relu(self.out[i](x))\n",
    "        out = self.out[-1](x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTNCI(nn.Module):    \n",
    "    def __init__(self,\n",
    "                 input_d, \n",
    "                 dims = None,\n",
    "                 out_spec = [{'manifold':'euclid', 'dim':[10]},\n",
    "                             {'manifold':'poincare', 'dim':[2]}],\n",
    "                 dropout_prob = 0.2):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.common_network = CommonLayer(input_d=input_d,\n",
    "                                          dims = dims,\n",
    "                                          dropout_prob=dropout_prob)\n",
    "        \n",
    "        self.out_layers = nn.ModuleList()\n",
    "        \n",
    "        for spec in out_spec:\n",
    "            self.out_layers.append(RegressionOutput(hidden_dim=dims[-1],\n",
    "                                              dims=spec['dim'],\n",
    "                                              manifold = spec['manifold']))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.common_network(x)\n",
    "        \n",
    "        output = []\n",
    "        \n",
    "        for layer in self.out_layers:\n",
    "            output.append(layer(x))\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geoopt.optim import RiemannianAdam\n",
    "\n",
    "out_spec = [{'manifold':'euclid', 'dim':[64, len(explicit_y_train['distributional'][0])]},\n",
    "            {'manifold':'poincare', 'dim':[128, len(explicit_y_train['hyperbolic'])]}]\n",
    "\n",
    "\n",
    "model = MTNCI(input_d=len(c.X_train[0]),\n",
    "              out_spec = out_spec,\n",
    "              dims = [512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = [1e-3,\n",
    "       0]\n",
    "\n",
    "optimizer = RiemannianAdam(model.parameters(), lr = lrs[0])\n",
    "regul = [0, 0, 2]\n",
    "llambda = 0.05\n",
    "\n",
    "epochs = 30\n",
    "\n",
    "min_loss = [100, 2000]\n",
    "min_val_loss = [100, 2000]\n",
    "best_sim = [-1, 4000]\n",
    "sims = [0, 0]\n",
    "sim = [0, 0]\n",
    "colored, val_colored = [], []\n",
    "checkpoint_path = './models/MTN'\n",
    "epochs_no_improve = 0\n",
    "n_epochs_stop = 20\n",
    "min_val_losses = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.95 GiB (GPU 0; 11.91 GiB total capacity; 8.65 GiB already allocated; 1.72 GiB free; 10.46 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-c2f02f2fc5fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Notebooks/pytorch/MTNCI_pytorch/MTNCI_pytorch_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-0bc8ae1cb81e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Notebooks/pytorch/MTNCI_pytorch/MTNCI_pytorch_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-4e06b52a4981>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Notebooks/pytorch/MTNCI_pytorch/MTNCI_pytorch_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-74f2ae903229>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mnonlin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonlin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mball\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mball\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         )\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-74f2ae903229>\u001b[0m in \u001b[0;36mmobius_linear\u001b[0;34m(input, weight, bias, nonlin, ball)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# package.nn.functional.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmobius_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonlin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mball\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgeoopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPoincareBall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mball\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmobius_matvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mball\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmobius_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Notebooks/pytorch/MTNCI_pytorch/MTNCI_pytorch_env/lib/python3.6/site-packages/geoopt/manifolds/poincare/__init__.py\u001b[0m in \u001b[0;36mmobius_matvec\u001b[0;34m(self, m, x, dim, project)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmobius_matvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Notebooks/pytorch/MTNCI_pytorch/MTNCI_pytorch_env/lib/python3.6/site-packages/geoopt/manifolds/poincare/math.py\u001b[0m in \u001b[0;36mproject\u001b[0;34m(x, c, dim, eps)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mprojected\u001b[0m \u001b[0mvector\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmanifold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_project\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Notebooks/pytorch/MTNCI_pytorch/MTNCI_pytorch_env/lib/python3.6/site-packages/geoopt/manifolds/poincare/math.py\u001b[0m in \u001b[0;36m_project\u001b[0;34m(x, c, dim, eps)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mmaxnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mcond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0mprojected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmaxnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprojected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.95 GiB (GPU 0; 11.91 GiB total capacity; 8.65 GiB already allocated; 1.72 GiB free; 10.46 MiB cached)"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    train_it = iter(trainloader)\n",
    "\n",
    "    for batch_iteration in range(len(trainloader)):\n",
    "        x, labels, outputs = next(train_it)\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        ######################\n",
    "        ####### TRAIN ########\n",
    "        ######################\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        model.train()\n",
    "        output = model(x)\n",
    "        output\n",
    "        \n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MTNCI_pytorch_kernel",
   "language": "python",
   "name": "mtnci_pytorch_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
